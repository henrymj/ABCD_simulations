{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy.solvers import solve\n",
    "from sympy import Symbol\n",
    "import scipy.stats as sstats\n",
    "\n",
    "from os import path\n",
    "\n",
    "from scripts.utils import SimulateData\n",
    "from stopsignalmetrics import SSRTmodel, StopData\n",
    "\n",
    "from scipy.stats import exponnorm, norm, norminvgauss\n",
    "from scipy import stats\n",
    "\n",
    "from batch_files.generate_remaining_sim_cmds import replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_MUS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Preprocessing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data for use by stopsignalmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/abcd_w_finger_press.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8464"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abcd_data.NARGUID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rt_col in ['go_rt_adjusted', 'stop_rt_adjusted']:\n",
    "    abcd_data.loc[abcd_data['finger_press'].isnull(), rt_col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data['block'] = np.NaN\n",
    "abcd_data.loc[abcd_data['TrialNum'] < 180, 'block'] = '1'\n",
    "abcd_data.loc[abcd_data['TrialNum'] >= 180, 'block'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data['choice_accuracy'] = np.where(\n",
    "    abcd_data['finger_press'].notnull(),\n",
    "    np.where(\n",
    "        abcd_data['finger_press']==abcd_data['correct_response'],\n",
    "        1,\n",
    "        0),\n",
    "    np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8464"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abcd_data.NARGUID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 replace IDs with ` (backticks) in them\n",
    "#### shell scripts do not interpret them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_backticks(string):\n",
    "    return string.replace('`', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_unique_IDs = abcd_data.NARGUID.unique()\n",
    "fix_id_map = {i:strip_backticks(i) for i in abcd_data.NARGUID.unique() if '`' in i}\n",
    "abcd_data.NARGUID = abcd_data.NARGUID.replace(fix_id_map)\n",
    "assert len(original_unique_IDs)==len(abcd_data.NARGUID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data.to_csv('abcd_data/minimal_abcd_with_issue_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Drop Issue 3 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data_w_issue_3 = pd.read_csv('abcd_data/minimal_abcd_with_issue_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0., nan])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abcd_data_w_issue_3['correct_go_response'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n affected: 226\n",
      "p affect: 0.03125432167058498\n",
      "n remaining: 8238\n"
     ]
    }
   ],
   "source": [
    "issue_3_people = abcd_data_w_issue_3.loc[(abcd_data_w_issue_3['stop_rt_adjusted'] < 50) & (abcd_data_w_issue_3['stop_rt_adjusted'] > 0) & (abcd_data_w_issue_3['SSDDur'] ==50), 'NARGUID'].unique()\n",
    "\n",
    "print('n affected:', len(issue_3_people))\n",
    "print('p affect:', len(issue_3_people)/ 7231)\n",
    "\n",
    "abcd_data = abcd_data_w_issue_3[~abcd_data_w_issue_3.NARGUID.isin(issue_3_people)].copy()\n",
    "print('n remaining:', abcd_data.NARGUID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data.to_csv('abcd_data/minimal_abcd_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Metrics for Simulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/minimal_abcd_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. get a distribution of mean go RTs and SSRTs to sample from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict = {\n",
    "   \"columns\": {\n",
    "      \"ID\": \"NARGUID\", #subject identifier\n",
    "      \"condition\": \"trial_type\", #col with trial types \n",
    "      \"correct_response\": \"correct_response\", #col with correct reponse codes\n",
    "      \"response\": \"finger_press\", #col with actual response codes \n",
    "      \"SSD\": \"SSDDur\", #col with stop signal delay \n",
    "      \"block\": \"block\", #col with which block a trial is accuring during\n",
    "      \"goRT\": \"go_rt_adjusted\", # col with go reaction time recording \n",
    "      \"stopRT\": \"stop_rt_adjusted\", #col with stop failure reaction time recording\n",
    "      \"choice_accuracy\": \"choice_accuracy\" #col with whether a response was correct\n",
    "   },\n",
    "   \"key_codes\": {\n",
    "      \"go\": \"GoTrial\", # cell values for go trials  \n",
    "      \"stop\": \"StopTrial\",  #cell values for stop trials \n",
    "      \"correct\": 1.0,\n",
    "       \"incorrect\": 0.0,\n",
    "       \"noResponse\": np.nan\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrymj/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/henrymj/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "abcd_ssrt = StopData(var_dict=variable_dict, compute_acc_col=False)\n",
    "\n",
    "abcd_proc = abcd_ssrt.fit_transform(abcd_data) \n",
    "\n",
    "ssrt_model = SSRTmodel(model='replacement')\n",
    "\n",
    "ssrt_metrics = ssrt_model.fit_transform(abcd_proc, level='group')\n",
    "\n",
    "problem_subs = ssrt_metrics[ssrt_metrics.SSRT.isnull()].index\n",
    "\n",
    "print(f'dropping {len(problem_subs)} subs for having P(respond|signal) == 1 or 0')\n",
    "\n",
    "ssrt_metrics = ssrt_metrics[ssrt_metrics.SSRT.notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssrt_metrics.to_csv('abcd_data/abcd_ssrt_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mus(sub_row):\n",
    "#     sub_row = sub_row.copy()\n",
    "#     mu_dict = {}\n",
    "#     # init go and stop vars\n",
    "#     g = Symbol('g')\n",
    "#     s = Symbol('s')\n",
    "    \n",
    "#     # formulas (must be solved as \"expression = 0\")\n",
    "#     # subject_{go/ss}rt = threshold/mu_go + nondecision_time\n",
    "#     # threshold = 100\n",
    "#     # nondecision_time = 50\n",
    "    \n",
    "#     go_sol = solve((sub_row['mean_go_RT'].values[0] - 50) * g - 100, g)\n",
    "# #     go_sol = solve(100/g + 50 - sub_row['mean_go_RT'].values[0], g)\n",
    "#     assert len(go_sol) == 1, f\"{len(go_sol)} solutions found based on {sub_row['mean_go_RT']}: {go_sol}\"\n",
    "#     mu_dict['go'] = float(go_sol[0])\n",
    "    \n",
    "#     stop_sol = solve(100/s + 50 - sub_row['SSRT'].values[0], s)\n",
    "#     assert len(stop_sol) == 1, f\"{len(stop_sol)} solutions found based on {sub_row['SSRT']}: {stop_sol}\"\n",
    "#     mu_dict['stop'] = float(stop_sol[0])\n",
    "    \n",
    "#     return mu_dict\n",
    "\n",
    "# mu_df = ssrt_metrics.groupby('ID').apply(get_mus)\n",
    "# mu_dict = mu_df.to_dict()\n",
    "# mu_dict['prob_subs'] = list(problem_subs)\n",
    "# mu_df = mu_df.apply(pd.Series)\n",
    "\n",
    "# json_mu_path = 'abcd_data/individual_mus.json'\n",
    "# with open(json_mu_path, 'w') as jp:\n",
    "#     json.dump(mu_dict, jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = sns.distplot(ssrt_metrics['SSRT'], kde=False, norm_hist=True, label='SSRT')\n",
    "ssrt_loc,ssrt_var = norm.fit(ssrt_metrics['SSRT'])\n",
    "xx = np.arange(-500, 3000, 1)\n",
    "ax.plot(xx, norm.pdf(xx, loc=ssrt_loc, scale=ssrt_var), 'k', lw=2)  \n",
    "_ = sns.distplot(ssrt_metrics['mean_go_RT'], kde=False,norm_hist=True, ax=ax, label='goRT')\n",
    "goRT_loc,goRT_var = norm.fit(ssrt_metrics['mean_go_RT'])\n",
    "ax.plot(xx, norm.pdf(xx, loc=goRT_loc, scale=goRT_var), 'k', lw=2) \n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating but giving a reasonable scale for the SSRT distribution\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = sns.distplot(ssrt_metrics['SSRT'], kde=False, norm_hist=True, label='SSRT')\n",
    "xx = np.arange(-500, 3000, 1)\n",
    "ax.plot(xx, norm.pdf(xx, loc=ssrt_loc, scale=85), 'k', lw=2)  \n",
    "_ = sns.distplot(ssrt_metrics['mean_go_RT'], kde=False,norm_hist=True, ax=ax, label='goRT')\n",
    "ax.plot(xx, norm.pdf(xx, loc=goRT_loc, scale=goRT_var), 'k', lw=2) \n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = sns.distplot(ssrt_metrics['SSRT'], kde=False, norm_hist=True, label='SSRT')\n",
    "xx = np.arange(-500, 3000, 1)\n",
    "ax.plot(xx, norm.pdf(xx, loc=ssrt_loc, scale=25), 'k', lw=2)  \n",
    "_ = sns.distplot(ssrt_metrics['mean_go_RT'], kde=False,norm_hist=True, ax=ax, label='goRT')\n",
    "ax.plot(xx, norm.pdf(xx, loc=goRT_loc, scale=goRT_var), 'k', lw=2) \n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. get SSD distributions per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SSD = 500 #for clipping distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/minimal_abcd_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSD_dist = abcd_data.groupby('NARGUID')['SSDDur'].value_counts(normalize=True)\n",
    "SSD_dist.name = 'proportion'\n",
    "SSD_dist = SSD_dist.reset_index()\n",
    "SSD_dist.to_csv(f'abcd_data/SSD_dist_by_subj_{MAX_SSD}Clip-False.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSD_dist_clipped = abcd_data.query(f\"(SSDDur <= {MAX_SSD}) | (trial_type=='GoTrial')\").groupby('NARGUID')['SSDDur'].value_counts(normalize=True)\n",
    "SSD_dist_clipped.name = 'proportion'\n",
    "SSD_dist_clipped = SSD_dist_clipped.reset_index()\n",
    "SSD_dist_clipped.to_csv(f'abcd_data/SSD_dist_by_subj_{MAX_SSD}Clip-True.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SSD_dist.query(f\"SSDDur > {MAX_SSD}\").NARGUID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Sample Mus if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSRT_SCALE = 0  # 85\n",
    "\n",
    "\n",
    "def convert_to_mu(rt, thresh=100, ndt=50):\n",
    "    # example solve:\n",
    "    # Threshold = mu * (rt - non-decision-time)\n",
    "    # Threshold / (rt - ndt) = mu\n",
    "    return thresh/(rt-ndt)\n",
    "\n",
    "def sample(mean, scale, ndt=50):\n",
    "    tmp = np.random.normal(loc=mean, scale=scale)\n",
    "    # if it is less that the non-decision-time, you get negative mus\n",
    "    # if it is close to the nondecision time, you get HUGE mus\n",
    "    while tmp < ndt+10: \n",
    "        tmp = np.random.normal(loc=mean, scale=scale)\n",
    "    return tmp\n",
    "\n",
    "write_out_path = 'abcd_data/assigned_mus.json'\n",
    "if not path.exists(write_out_path) or OVERWRITE_MUS:\n",
    "    print('assigning mus')\n",
    "    mus_dict = {}\n",
    "    for sub in SSD_dist.NARGUID.unique():\n",
    "        mus_dict[sub] = {}\n",
    "        mus_dict[sub]['goRT'] = sample(mean=goRT_loc, scale=goRT_var)\n",
    "        mus_dict[sub]['go'] = convert_to_mu(mus_dict[sub]['goRT'])\n",
    "        mus_dict[sub]['SSRT'] = sample(mean=ssrt_loc, scale=SSRT_SCALE) # HARD CODED SCALE FOR BETTER FIT\n",
    "        mus_dict[sub]['stop'] = convert_to_mu(mus_dict[sub]['SSRT']) \n",
    "    with open(write_out_path, 'w') as jp:\n",
    "        json.dump(mus_dict, jp)    \n",
    "            \n",
    "    # visualize\n",
    "    mu_df = pd.DataFrame(mus_dict).T\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    ax = sns.distplot(mu_df['go'], kde=False, norm_hist=True, label='go')\n",
    "    _ = sns.distplot(mu_df['stop'], kde=False,norm_hist=True, ax=ax, label='stop')\n",
    "    _ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['003RTV85', '007W6H7B', '00CY2MDM', ..., 'wzrf2ge6', 'x8k59',\n",
       "       'xxmy9wd8'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSD_dist.NARGUID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exgauss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/minimal_abcd_clean.csv')\n",
    "SSD0_RTs = abcd_data.query(\n",
    "    \"SSDDur == 0.0 and correct_stop==0.0\"\n",
    "    ).stop_rt_adjusted.values\n",
    "\n",
    "FIT_K, FIT_LOC, FIT_SCALE = sstats.exponnorm.fit(SSD0_RTs)\n",
    "FIT_LAMBDA = 1/(FIT_K*FIT_SCALE)\n",
    "FIT_BETA = 1/FIT_LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "exgaus_params = {\n",
    "    'K': FIT_K,\n",
    "    'loc': FIT_LOC,\n",
    "    'scale': FIT_SCALE,\n",
    "    'lambda': FIT_LAMBDA,\n",
    "    'beta': FIT_BETA,\n",
    "}\n",
    "\n",
    "with open('abcd_data/exgauss_params.json', 'w') as f:\n",
    "    json.dump(exgaus_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. P(guess|SSD) for mixture distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/minimal_abcd_clean.csv')\n",
    "SSDs = abcd_data.SSDDur.unique()\n",
    "SSDs = [i for i in SSDs if i == i]\n",
    "SSDs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_SSD = pd.DataFrame()\n",
    "for ssd in SSDs:\n",
    "    curr_means = abcd_data.query(\n",
    "        \"SSDDur == %s and correct_stop==0.0\" % ssd\n",
    "    ).groupby('NARGUID').mean()['choice_accuracy']\n",
    "    curr_means.name = ssd\n",
    "    acc_per_SSD = pd.concat([acc_per_SSD, curr_means], 1, sort=True)\n",
    "\n",
    "go_accs = abcd_data.query(\n",
    "        \"trial_type == 'GoTrial' and correct_go_response in [1.0, 0.0]\"\n",
    "    ).groupby('NARGUID').mean()['choice_accuracy']\n",
    "go_accs.name = -1\n",
    "acc_per_SSD = pd.concat([acc_per_SSD, go_accs], 1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0      0.499410\n",
       " 50.0     0.561566\n",
       " 100.0    0.656870\n",
       " 150.0    0.723856\n",
       " 200.0    0.795379\n",
       " 250.0    0.830639\n",
       " 300.0    0.860157\n",
       " 350.0    0.884024\n",
       " 400.0    0.895152\n",
       " 450.0    0.906854\n",
       " 500.0    0.912347\n",
       " 550.0    0.919252\n",
       " 600.0    0.917789\n",
       " 650.0    0.914306\n",
       " 700.0    0.894193\n",
       " 750.0    0.904812\n",
       " 800.0    0.852174\n",
       " 850.0    0.831197\n",
       " 900.0    0.817350\n",
       "-1.0      0.919088\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_per_SSD.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Symbol('p')\n",
    "guess_mean = acc_per_SSD.mean()[0.0]\n",
    "go_mean = acc_per_SSD.mean()[-1]\n",
    "p_guess_per_SSD = {}\n",
    "for ssd in SSDs:\n",
    "    curr_mean = acc_per_SSD.mean()[ssd]\n",
    "    solution = solve(p*guess_mean + (1-p)*go_mean - curr_mean, p)\n",
    "    assert len(solution) == 1\n",
    "    p_guess_per_SSD[ssd] = solution[0]\n",
    "p_guess_df = pd.DataFrame(p_guess_per_SSD, index=['p_guess'])\n",
    "p_guess_df.to_csv('abcd_data/p_guess_per_ssd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 1.0,\n",
       " 50.0: 0.8518966881510508,\n",
       " 100.0: 0.6248081425758761,\n",
       " 150.0: 0.46519470731379453,\n",
       " 200.0: 0.2947710624963631,\n",
       " 250.0: 0.21075535798552303,\n",
       " 300.0: 0.1404209047269027,\n",
       " 350.0: 0.08354920017624702,\n",
       " 400.0: 0.05703409119007931,\n",
       " 450.0: 0.029151024358994575,\n",
       " 500.0: 0.016063618909064378,\n",
       " 550.0: -0.0003910068585019575,\n",
       " 600.0: 0.0030962512655911116,\n",
       " 650.0: 0.01139533818314855,\n",
       " 700.0: 0.059318925632538,\n",
       " 750.0: 0.0340178091093458,\n",
       " 800.0: 0.15944204679687593,\n",
       " 850.0: 0.20942638758940402,\n",
       " 900.0: 0.24241997384504005}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{col: float(p_guess_df[col].values[0]) for col\n",
    "                      in p_guess_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_guess_df2 = pd.read_csv('abcd_data/p_guess_per_ssd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>50.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>150.0</th>\n",
       "      <th>200.0</th>\n",
       "      <th>250.0</th>\n",
       "      <th>300.0</th>\n",
       "      <th>350.0</th>\n",
       "      <th>400.0</th>\n",
       "      <th>450.0</th>\n",
       "      <th>500.0</th>\n",
       "      <th>550.0</th>\n",
       "      <th>600.0</th>\n",
       "      <th>650.0</th>\n",
       "      <th>700.0</th>\n",
       "      <th>750.0</th>\n",
       "      <th>800.0</th>\n",
       "      <th>850.0</th>\n",
       "      <th>900.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.624808</td>\n",
       "      <td>0.465195</td>\n",
       "      <td>0.294771</td>\n",
       "      <td>0.210755</td>\n",
       "      <td>0.140421</td>\n",
       "      <td>0.083549</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>0.029151</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.059319</td>\n",
       "      <td>0.034018</td>\n",
       "      <td>0.159442</td>\n",
       "      <td>0.209426</td>\n",
       "      <td>0.24242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0      50.0     100.0     150.0     200.0     250.0     300.0     350.0  \\\n",
       "0  1.0  0.851897  0.624808  0.465195  0.294771  0.210755  0.140421  0.083549   \n",
       "\n",
       "      400.0     450.0     500.0     550.0     600.0     650.0     700.0  \\\n",
       "0  0.057034  0.029151  0.016064 -0.000391  0.003096  0.011395  0.059319   \n",
       "\n",
       "      750.0     800.0     850.0    900.0  \n",
       "0  0.034018  0.159442  0.209426  0.24242  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_guess_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inhibition function (p(respond|SSD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_resp_per_SSD(data, SSDs):\n",
    "    data = data.copy()\n",
    "    out_dict = {}\n",
    "    for ssd in SSDs:\n",
    "        curr_data = data.query(\n",
    "            \"SSDDur == %s\" % ssd\n",
    "        )\n",
    "        if len(curr_data) == 0:\n",
    "            out_dict[ssd] = np.nan\n",
    "        else:\n",
    "            out_dict[ssd] = len(curr_data.query(\"correct_stop == 0.0\")) / len(curr_data)\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/minimal_abcd_clean.csv')\n",
    "SSDs = [i for i in abcd_data.SSDDur.unique() if i==i]\n",
    "ssd_resp_dict = abcd_data.groupby('NARGUID').apply(get_p_resp_per_SSD, SSDs)\n",
    "ssd_resp_df = ssd_resp_dict.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_resp_melt = ssd_resp_df.reset_index().melt(id_vars='NARGUID', value_vars=ssd_resp_df.columns, var_name='SSD', value_name='p_respond' )\n",
    "ssd_resp_melt['underlying distribution'] = 'ABCD data'\n",
    "ssd_resp_melt.to_csv('abcd_data/abcd_inhib_func_per_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_inhib_func = pd.DataFrame(ssd_resp_df.mean())\n",
    "abcd_inhib_func.index.name = 'SSD'\n",
    "abcd_inhib_func.columns = ['p_respond']\n",
    "abcd_inhib_func = abcd_inhib_func.reset_index()\n",
    "abcd_inhib_func['underlying distribution'] = 'ABCD data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_inhib_func.to_csv('abcd_data/abcd_inhib_func.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. build run_sims.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_data = pd.read_csv('abcd_data/minimal_abcd_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "narguids = abcd_data.NARGUID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsubs_per_job = 48\n",
    "njobs_per_node = 36\n",
    "nlines = 0\n",
    "with open('batch_files/TACC/run_sims.sh', 'w') as f:\n",
    "    for start_idx in range(0, len(narguids), nsubs_per_job):\n",
    "        end_idx = start_idx + nsubs_per_job\n",
    "        if end_idx > len(narguids):\n",
    "            end_idx = len(narguids)\n",
    "        substr = ' '.join(narguids[start_idx:end_idx])\n",
    "        f.write(f'python simulate_individuals.py --subjects {substr}\\n')\n",
    "        nlines += 1\n",
    "nlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#SBATCH -N 5 # number of nodes requested - set to ceil(n rows in command script / 36)\n",
      "\n",
      "#SBATCH -n 172 # total number of mpi tasks requested - set to n rows in command script\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_line_str = '#SBATCH -N %d # number of nodes requested - set to ceil(n rows in command script / 36)\\n' % int(np.ceil(nlines/njobs_per_node))\n",
    "n_line_str = '#SBATCH -n %s # total number of mpi tasks requested - set to n rows in command script\\n' % nlines\n",
    "\n",
    "replace(\n",
    "    'batch_files/TACC/launch_sim_cmds.slurm',\n",
    "    '#SBATCH -N',\n",
    "    N_line_str)\n",
    "replace(\n",
    "    'batch_files/TACC/launch_sim_cmds.slurm',\n",
    "    '#SBATCH -n',\n",
    "    n_line_str)\n",
    "# prints so you can compare the lines of the slurm file\n",
    "print(N_line_str)\n",
    "print(n_line_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sherlock version\n",
    "\n",
    "# sher_sim_file = 'sherlock_run_sims.batch'\n",
    "\n",
    "# N_line_str = '#SBATCH -N %d # number of nodes requested - set to ceil(n rows in command script / 36)\\n' % int(np.ceil(nlines/njobs_per_node))\n",
    "# n_line_str = '#SBATCH -n %s # total number of mpi tasks requested - set to n rows in command script\\n' % nlines\n",
    "\n",
    "# replace(\n",
    "#     sher_sim_file,\n",
    "#     '#SBATCH -N',\n",
    "#     N_line_str)\n",
    "# replace(\n",
    "#     sher_sim_file,\n",
    "#     '#SBATCH -n',\n",
    "#     n_line_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sher_sim_file = 'batch_files/sherlock/sherlock_run_sims%d.batch'\n",
    "\n",
    "ABCD_LOC = '/oak/stanford/groups/russpold/users/henrymj/ABCD_simulations/abcd_data'\n",
    "OUT_LOC = '/oak/stanford/groups/russpold/users/henrymj/ABCD_simulations/simulated_data/individual_data'\n",
    "\n",
    "sher_header = '''#!/bin/bash\n",
    "#SBATCH --job-name=sims\n",
    "#SBATCH --output=.out/sims%d.out\n",
    "#SBATCH --error=.err/sims%d.err\n",
    "#SBATCH --time=3:00:00\n",
    "#SBATCH --mail-type=END\n",
    "#SBATCH --mail-user=henrymj@stanford.edu\n",
    "#SBATCH -N 1 # number of nodes requested - set to ceil(n rows in command script / 24)\n",
    "#SBATCH -n %d # total number of mpi tasks requested - set to n rows in command script\n",
    "#SBATCH -p russpold,normal\n",
    "# Job Submission\n",
    "#-----------\n",
    "export PYTHONPATH=\"\"\n",
    "\n",
    "source ~/miniconda3/etc/profile.d/conda.sh \n",
    "conda activate py3-env\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubs_per_job = 48\n",
    "njobs_per_node = 24\n",
    "nlines = 0\n",
    "batch_counter = 0\n",
    "\n",
    "file_str = sher_header\n",
    "for start_idx in range(0, len(narguids), nsubs_per_job):\n",
    "    end_idx = start_idx + nsubs_per_job\n",
    "    if end_idx > len(narguids):\n",
    "        end_idx = len(narguids)\n",
    "    substr = ' '.join(narguids[start_idx:end_idx])\n",
    "    file_str += (f'eval \"python ../../scripts/simulate_individuals.py --abcd_dir {ABCD_LOC} --out_dir {OUT_LOC} --subjects {substr}\" &\\n')\n",
    "    nlines += 1\n",
    "    if nlines == 24:\n",
    "        with open(sher_sim_file % batch_counter, 'w') as f:\n",
    "            f.write(file_str % (batch_counter, batch_counter, nlines))\n",
    "            f.write(f'wait\\n')\n",
    "        # reset for new batch file\n",
    "        file_str = sher_header\n",
    "        nlines = 0\n",
    "        batch_counter += 1\n",
    "# at end, if things didn't split out evenly, write out the remaining subs\n",
    "if nlines > 0:\n",
    "    with open(sher_sim_file % batch_counter, 'w') as f:\n",
    "        f.write(file_str % (batch_counter, batch_counter, nlines))\n",
    "        f.write(f'wait\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsubs_per_job = 48\n",
    "# njobs_per_node = 24\n",
    "# nlines = 0\n",
    "# with open(sher_sim_file, 'a') as f:\n",
    "#     for start_idx in range(0, len(narguids), nsubs_per_job):\n",
    "#         end_idx = start_idx + nsubs_per_job\n",
    "#         if end_idx > len(narguids):\n",
    "#             end_idx = len(narguids)\n",
    "#         substr = ' '.join(narguids[start_idx:end_idx])\n",
    "#         f.write(f'eval \"python simulate_individuals.py --subjects {substr}\" &\\n')\n",
    "#         nlines += 1\n",
    "#         if nlines = 24:\n",
    "#             break\n",
    "#     f.write(f'wait\\n')\n",
    "# nlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
